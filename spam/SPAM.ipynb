{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPAM.ipynb",
      "provenance": [],
      "mount_file_id": "1dDIGygeTYfru0ailQ0C40bwACNQ2Ge-7",
      "authorship_tag": "ABX9TyN8rJdY4KDtR2PuARSaauAV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anioki/ML_training_projects/blob/main/spam/SPAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwQ_IdY9Utv6"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX4Bg_aDUvdc"
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Br-1bvAUyh0"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugzU9Wr8U1ur",
        "outputId": "2a905c98-1fec-43c3-c2a1-7379ed08a2f6"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                                           title                                              size  lastUpdated          downloadCount  \n",
            "------------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
            "gpreda/reddit-vaccine-myths                                   Reddit Vaccine Myths                              231KB  2021-06-22 06:09:25           8016  \n",
            "crowww/a-large-scale-fish-dataset                             A Large Scale Fish Dataset                          3GB  2021-04-28 17:03:01           4892  \n",
            "imsparsh/musicnet-dataset                                     MusicNet Dataset                                   22GB  2021-02-18 14:12:19           1657  \n",
            "dhruvildave/wikibooks-dataset                                 Wikibooks Dataset                                   1GB  2021-06-21 13:35:12           2271  \n",
            "mathurinache/twitter-edge-nodes                               Twitter Edge Nodes                                342MB  2021-03-08 06:43:04            545  \n",
            "fatiimaezzahra/famous-iconic-women                            Famous Iconic Women                               838MB  2021-02-28 14:56:00            816  \n",
            "promptcloud/careerbuilder-job-listing-2020                    Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52           1118  \n",
            "coloradokb/dandelionimages                                    DandelionImages                                     4GB  2021-02-19 20:03:47            512  \n",
            "nickuzmenkov/nih-chest-xrays-tfrecords                        NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23            613  \n",
            "alsgroup/end-als                                              End ALS Kaggle Challenge                           12GB  2021-04-08 12:16:37            737  \n",
            "simiotic/github-code-snippets                                 GitHub Code Snippets                                7GB  2021-03-03 11:34:39            168  \n",
            "mathurinache/the-lj-speech-dataset                            The LJ Speech Dataset                               3GB  2021-02-15 09:19:54            204  \n",
            "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet    LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40            125  \n",
            "nickuzmenkov/ranzcr-clip-kfold-tfrecords                      RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51             85  \n",
            "stuartjames/lights                                            LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26             80  \n",
            "imsparsh/accentdb-core-extended                               AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54             84  \n",
            "jessicali9530/animal-crossing-new-horizons-nookplaza-dataset  Animal Crossing New Horizons Catalog              577KB  2021-06-08 15:05:09           4011  \n",
            "datasnaek/youtube-new                                         Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         142977  \n",
            "zynicide/wine-reviews                                         Wine Reviews                                       51MB  2017-11-27 17:08:04         138868  \n",
            "residentmario/ramen-ratings                                   Ramen Ratings                                      40KB  2018-01-11 16:04:39          24229  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYS6m6JSU58c",
        "outputId": "37bd56e2-c581-4ebe-f7f2-0ed91a9e04bf"
      },
      "source": [
        "! kaggle datasets download -d uciml/sms-spam-collection-dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sms-spam-collection-dataset.zip to /content\n",
            "\r  0% 0.00/211k [00:00<?, ?B/s]\n",
            "\r100% 211k/211k [00:00<00:00, 30.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfo_emb6U7N2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5be650f-94c5-4f6e-ba8f-a5abbbb621a8"
      },
      "source": [
        "! mkdir data\n",
        "! unzip sms-spam-collection-dataset.zip -d data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sms-spam-collection-dataset.zip\n",
            "  inflating: data/spam.csv           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN9YlvDHVFWx"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import BernoulliNB"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "isGbRnB1VG_S",
        "outputId": "5681fb65-3f8e-4023-cbe9-e0df3099968d"
      },
      "source": [
        "df = pd.read_csv('/content/data/spam.csv', encoding=\"ISO-8859-1\")\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        v1  ... Unnamed: 4\n",
              "0      ham  ...        NaN\n",
              "1      ham  ...        NaN\n",
              "2     spam  ...        NaN\n",
              "3      ham  ...        NaN\n",
              "4      ham  ...        NaN\n",
              "...    ...  ...        ...\n",
              "5567  spam  ...        NaN\n",
              "5568   ham  ...        NaN\n",
              "5569   ham  ...        NaN\n",
              "5570   ham  ...        NaN\n",
              "5571   ham  ...        NaN\n",
              "\n",
              "[5572 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CMkrlaQpK0y"
      },
      "source": [
        "X = df[\"v2\"].values\n",
        "y = df[\"v1\"].values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQijiFdYpTaU"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VKpyL8BrrrD"
      },
      "source": [
        "#Data Preprocessing and Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJflmPRXpVHi"
      },
      "source": [
        "bernoulli_nb_pipeline = make_pipeline(\n",
        "    CountVectorizer(binary=True), BernoulliNB(alpha=10**-2)\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsWY2HofozLY",
        "outputId": "966dc2b4-1ed2-4165-d456-ed1bcd8cdeef"
      },
      "source": [
        "bernoulli_nb_pipeline.fit(X_train, y_train)\n",
        "y_test_pred = bernoulli_nb_pipeline.predict(X_test)\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      1.00      0.99       966\n",
            "        spam       0.99      0.93      0.96       149\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.99      0.96      0.98      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}